{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and Analyse Project:\n",
    "\n",
    "# Data Wrangle Report\n",
    "\n",
    "### By Ketan Ramaneti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "> This project involves wrangling data from various sources associated with tweets from the twitter account @dog_rates. WeRateDogs rate's pictures of users' dogs in a humorous manner. Most often they give rating more than 10/10. <br> <br>\n",
    "> After scraping the data from various sources listed in the Udacity's Project Details, the data was cleaned after identifying the quality and tidiness issues. <br> <br>\n",
    "> Three visualisations were created to analyse the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data:\n",
    ">  Data was gathered from 3 different sources: \n",
    "\n",
    "1. enhanced-twitter-archive.csv file was provided by Udacity. This file includes variables like tweet id, timestamp, text rating etc.\n",
    "2. Additional data like favorite count and retweet count were gathered using Twitter API.\n",
    "3. The tweet image predictions file was downloaded programmatically using Requests library from Udacity's servers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing Data:\n",
    "> Assesment was performed using the following methods of pandas: <br>\n",
    "\n",
    "1. head()\n",
    "2. sample()\n",
    "3. info()\n",
    "4. describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Tidiness issues cleand:\n",
    "\n",
    "* Combining all dataframes obtained from various methods into a single data frame.\n",
    "* Combining 4 variables about dog type into 1 column 'dog_stage'.\n",
    "* Some of the dog stages were mentioned with more than one dog stage. This was solved by giving the dog stage's value as 'multiple'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Quality Issues which were cleaned\n",
    "\n",
    "1. Data containing retweets were removed.\n",
    "2. Tweet ID was incorrect data type.\n",
    "3. Timestamp was incorrect data type.\n",
    "4. Name contained string \"None\" instead of NaN\n",
    "5. Name contained various inaccuracies.\n",
    "6. Ratings were unstandardised.\n",
    "7. Name O'Malley was incorrectly extracted as 'O'.\n",
    "8. Some of the ratings were incorrectly extracted.\n",
    "7. Unnecessory columns were present.\n",
    "8. Duplicate jpg_urls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data:\n",
    "> Methods and techniques used:\n",
    "\n",
    "* merge()\n",
    "* rename()\n",
    "* reduce()\n",
    "* extract()\n",
    "* .loc[]\n",
    "* value_counts()\n",
    "* duplicated()\n",
    "* astype()\n",
    "* dtypes\n",
    "* to_datetime()\n",
    "* islower()\n",
    "* index\n",
    "* replace()\n",
    "* .str.contains()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "> Rarely, the data we want to analyse comes from a single source and is already tidy. This project clearly emphasized that various sources are needed from which data can be scraped using python and it's various libraries.\n",
    "<br>\n",
    "> Data can be assesed, cleaned and visualised using python and it's libraries such as pandas, numpy, matplotlib etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
